可视化编程是将代码组织成特定的数据结构，呈现在界面上，帮助使用者以非编码或极少编码的方式完成功能开发。

[https://baike.baidu.com/item/%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BC%96%E7%A8%8B/9006028?fr=aladdin](https://baike.baidu.com/item/%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BC%96%E7%A8%8B/9006028?fr=aladdin)

百科的定义是，以“所见即所得”的编程思想为原则，力图实现编程工作的可视化，即随时可以看到结果，程序与结果的调整同步。

简简单单“同步“两字，在实践过程中可谓呕心沥血。同步包括的含义是目标工程的代码和界面呈现的数据接口始终保持一致。牵涉到数据结构的定义和通讯的实时性，正反解析过程，增删改查对数据结构和最终代码的影响，通篇实践可谓都是为了达到”同步“这一目的。

特点是两个方面：一是基于	[面向对象](https://baike.baidu.com/item/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1)	的思想，引入了类的概念和	[事件驱动](https://baike.baidu.com/item/%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8)	；二是基于	[面向过程](https://baike.baidu.com/item/%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B)	的思想，程序开发过程一般遵循以下步骤，即先进行界面的绘制工作，再基于事件编写程序代码，以响应鼠标、键盘的各种动作。

第一方面即面向对象的数据结构，easy-bff通过十几种数据模型表达了bff开发所包括的概念。

第二方面即界面操作流程，客户端存储，通讯，服务端存储，codegen正写入等。

# 双端与长连接
因为文件读写只能在服务端完成，所以easy-bff拆分为了三个子项目：用于界面呈现的客户端easy-bff-client，用于文件读写与数据存储的服务端easy-bff-server，以及客户端和服务端间共享的模块easy-bff-share。

可视化编程是单客户端对单服务端的，所以只需提供一个连接即可。我们使用webSocket长连接。	长连接指在一个连接上可以连续发送多个	[数据包](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%8C%85/489739)	，在连接保持期间，如果没有数据包发送，需要双方发链路检测包。

[https://baike.baidu.com/item/%E9%95%BF%E8%BF%9E%E6%8E%A5](https://baike.baidu.com/item/%E9%95%BF%E8%BF%9E%E6%8E%A5)

就是说通讯数据包是不需要响应的，这符合实际情况，比如服务端可以连续多次要求客户端弹框显示消息。客户端和服务端定义各自的reciever处理消息。

# 共享模块
客户端和服务端有很多功能是共享的，主要有：数据模型，代码生成器，前端数据库，枚举，常量，工具函数，数据传输对象等。

这些共享内容放在easy-bff-share项目中，客户端和服务端安装这个私包调用。

后续详述这些共享模块。

# 传输与扁平化模型设计
开篇提到可视化编程围绕“同步”二字。同步的介质是数据模型。

只要数据模型的数据是一致的，那么客户端可以根据这份数据模型渲染界面，服务端可以codegen这份数据生成目标代码。服务端重新启动时，又可以将代码反解析成数据模型，客户端再根据数据模型渲染界面，达到无限的同步。

双端的同步是需要网络传输的，传输内容只能是字符串，所以一定是同步传输前将对象转换成json字符串，另一头再将json字符串parse成对象，完成数据结构的同步。

然而可视化编程的有一个致命的问题：数据模型大量存在**循环依赖。**

比如一个service里面有fetcherList，而每一个fetcher又需要反向知道我在哪一个service里面。这样Service依赖Fetcher，Fetcher依赖Service。

存在循环依赖的话，传输时转json就死循环了。

为了解决这一问题，我们设计了扁平化的数据模型，并引进前端数据库。

对象A对对象B形成依赖时，A中仅使用id指向B，而具体B的内容是通过函数的形式来获得的。

```
  defineId?: string; // 最外层类型定义
  get define(): Define {
    return this.searchDatabase(this.defineId);
  }
```
比如上面，对外部类Define形成依赖，仅存储defineId，不存储具体对象。
当需要对象的时候，使用getter函数获取，getter函数中搜索前端数据库。

这样在网络传输的时候就仅传输id了，达到数据同步的目的。

# 前端数据库设计
数据库的特点是两个表结构间通过外键的形式将多个数据结构串联起来。一个数据表的一条数据无需知道另一个数据表那条数据的全部信息，只需要知道它的id就可以。最终查询时再用sql语句串联起来，或者多次查询在业务层拼装等。

这种数据库模式可以完美地解决我们循环依赖导致无法传输的问题。

Map使node拥有类数据库功能。

```
export const mainTable: Map<string, BaseModel> = new Map<string, BaseModel>();
```
Map存储了所有扁平化的记录，Map键是id，值是扁平化对象。各对象通过id的外键形成大网，连结了网上各种各样的节点。
网络传输时，发送方将整张大网或部分增量网完整传输，接收方将大网写入数据库中，写入后外键id都已经结好了，getter轻松获取，获取后创建对象存入本地的数据库。

```
  createByNet(netModel: BaseModel): BaseModel {
    const newModel = this.createModelByModelType(netModel.modelType);
    if (!newModel) return null;
    for (const key in netModel) {
      newModel[key] = netModel[key];
    }
    this._insertToDbByModelType(netModel.modelType, newModel);
  }
```
弱类型遍历所有的键，克隆到新的对象，然后存入数据库。
既然是数据库就有增删改查。

1. 新增
```
  insert(newModel: BaseModel) {
    mainTable.set(newModel.id, newModel);
  }
```
2. 删除
```
  delete(id: string) {
    mainTable.delete(id);
  }
```
3. 修改
```
  update(newModel: BaseModel) {
    mainTable.set(newModel.id, newModel);
  }
```
4. 查询
```
  select(id: string): BaseModel {
    return mainTable.get(id) as any;
  }
  selectAll(): BaseModel[] {
    return Array.from(mainTable.values());
  }
```
# 扁平化编辑傀儡
前端开发中有经典的编辑傀儡问题：编辑页面中，如果直接在数据模型上操作数据，那么编辑取消的时候就无法退回在原先的数据了。所以编辑页中，开始编辑时都会克隆出一份编辑傀儡，在傀儡对象上操作数据。编辑取消时退回原对象；编辑保存时将傀儡混入到原对象。

可视化编程更为特殊，编辑傀儡是扁平的。对象间的依赖关系是通过外键来连结的。那么不管是克隆傀儡，还是傀儡混入原对象，情况都完全不同了。

首先是克隆。定义专用于编辑和新增都傀儡数据库DummyTable，及对应的DummyService。

创建傀儡函数

```
  createDummy<T>(modelType: MODEL_TYPE): T {
    const newModel = this.createModelByModelType(modelType);
    if (!newModel) return null;
    newModel.id = makeRandomHash();
    newModel.isDummy = true;
    dbDummyService.insert(newModel);
    return newModel as any;
  }
```
编辑傀儡是根据一个原先对象克隆出来的，原先对象又是通过外键编织的，所以克隆过程是一个深度遍历，定义class Weaver，从原对象网，编织一个傀儡网。
```
class Weaver {
  constructor(id: string, option: IOption) {
    this.loopPutModelMapInDb(this.topModel);
    this.createDummyModels();
    this.weaveIdMap();
  }
}
```
1. 深度遍历这个对象，找到所有牵涉到的数据库条目，并存放到一个临时Map。
2. 对象克隆，弱类型遍历键实例化一个新对象。如果是外键，存住dummyRegionId，以备后续复原傀儡。
3. 编织外键。现在的外键还是原对象对应的外键，要从临时Map找到要的那个id，结成新网。遍历这些傀儡，从其他傀儡中找dummyRegionId对应的id，连结新外键。

克隆完了要在保存时傀儡转正，网络传输并写入到正式库中。先网络传输，因为如果服务器保存失败那么需要退档，傀儡还是傀儡。

尝试转正时，读取傀儡数据库全部条目，准备网络传输。传输前再遍历一次校准id。因为如果是新增的，那么外键在傀儡数据库中，如果是编辑的，那么外键是在主数据库里的。id需要还原。

```
    const baby = dbFactory.createModelByModelType(dummy.modelType);
    baby.id = dummy.dummyRegionId || dummy.id; // 优选源id 没有源id的话说明是新增的 取自身id
```
定义一个新生婴儿的概念。防止胎死腹中污染原来的对象导致不能还原。
网络传输这些babies，另一头服务端接到这些babies，和先前一样插入正式表。然后走codegen，编译等一系列流程，如果编译通过，告知客户端保存成功，客户端再傀儡转正，销毁傀儡表。傀儡转正逻辑：简单插入

```
function updateDb(babies: BaseModel[]) {
  babies.forEach(baby => {
    dbFactory.insertOrUpdate(baby);
  });
  dbDummyService.clear();
}
```
# 数据同步
# 词法解析树反解析
可视化编程同步的其中一个问题时，如果识别已有的文件，表现成解析后的数据结构。只有反解析成功才可以后续的编辑。反解析是由13个不同层次的Parser组成的。

![图片](https://uploader.shimo.im/f/PK3a5bpN9NQZJcBI.png!thumbnail)

反解析过程是使用typescript模块的Program实现的。typescript获得的是ts的ast，而我们需要的是bff层的ast，有一个翻译的过程。翻译过程如下图：

![图片](https://uploader.shimo.im/f/3SMw5wDBOJQnJBfS.png!thumbnail)

typescript模块实现ts文件经过ts parser获得ts ast的过程。

反解析模块实现ts ast经过bff parser获得bff ast的过程。

todo...

# 前端正写入
codegen 代码生成 取名是来自Vue的 codeGenerator缩写

生成6组文件：

1. service文件 服务逻辑
2. controller文件 路由控制
3. dto文件 入参数据类型
4. vo文件 出参数据类型
5. doc文件 wiki文档
6. unitTest文件 单元测试文件

每组文件都是根据不同逻辑的字符串拼接。

![图片](https://uploader.shimo.im/f/ami2K4Z2IG8Xc8vk.png!thumbnail)

其中service文件的逻辑是最复杂的，内容最多，数据结构最复杂。主体分为主函数部分和各个fetcher的部分。一段一段地分步骤处理，最后合并成最终的文件。举个例子，service总体逻辑：

```
export default function(service: Service): string {
  let ret: string = `
${genImportBlock(service)}
${genExportBlock(service)}
${service.fetcherList.map(fetcher => genFetcher(service, fetcher)).join('\n')}  
`;
  ret = lint(ret);
  return ret;
}
```
获取import的部分，获取export的部分，再获取fetcher的部分，最后总的合并。
对象service具备了数据结构所有的内容，内部的函数根据service变成字符串，以beforeFetch钩子函数为例，逐层往里生成字符串。

```
export default function(service: Service, fetcher: Fetcher): string {
  const hook = fetcher.beforeFetcherHook;
  if (!hook) return '';
  return `
  beforeFetch(dto: ${fetcher.dtoType.getRefText()}): ${fetcher.dubboDtoType.getRefText()} {
    ${getDepList(hook)}
    ${hook.coreText}
  }
`;
}
```
